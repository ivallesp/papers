# Paper **Notes**

This repository contains my personal **Notes** about the papers I read. The papers below belong to different subfields of artificial intelligence (e.g. deep learning and reinforcement learning).

[[**Notes**](assets/vaswani2017.md)] [[Paper](https://arxiv.org/abs/1706.03762)] – 2017 – **Attention Is All You Need** – Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin – *Neural Information Processing Systems (NIPS) 2017*

[[**Notes**](assets/gehring2017.md)] [[Paper](https://arxiv.org/abs/1705.03122)] – 2017 – **Convolutional Sequence to Sequence Learning** – Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann N. Dauphin – *International Conference of Machine Learning (ICML) 2017*

[[**Notes**](assets/riedmiller2005.md)] [[Paper](http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf)] – 2005 – **Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method** – Martin Riedmiller – *Springer-Verlag Berlin Heidelberg 2005*

[[**Notes**](assets/dulacarnold2019.md)] [[Paper](https://arxiv.org/abs/1904.12901)] – 2019 – **Challenges of Real-World Reinforcement Learning** – Gabriel Dulac-Arnold, Daniel Mankowitz, Todd Hester – *International Conference of Machine Learning (ICML) 2019*

[[**Notes**](assets/fujimoto2019.md)] [[Paper](https://arxiv.org/abs/1812.02900)] – 2019 – **Off-Policy Deep Reinforcement Learning without Exploration** – Scott Fujimoto, David Meger, Doina Precup – *ICML 2019*

[[**Notes**](assets/jaques2019.md)] [[Paper](https://arxiv.org/abs/1907.00456)] – 2019 – **Way Off-Policy Batch Reinforcement Learning of Implicit Human Preferences in Dialog** – Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard – *Cambridge, preprint. Under review*

[[**Notes**](assets/agarwal2019.md)] [[Paper](https://arxiv.org/abs/1907.04543)] – 2019 – **Striving for simplicity in off-policy deep reinforcement learning** – Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi – *Neural Information Processing Systems (NeurIPS) 2019*

[[**Notes**](assets/jiang2016.md)] [[Paper](https://arxiv.org/abs/1511.03722)] – 2016 – **Doubly Robust Off-Policy Value Evaluation for Reinforcement Learning** – Nan Jiang and Lihong Li – *Proceedings of the 33rd International Conference of Machine Learning*

[[**Notes**](assets/kasim2020.md)] [[Paper](https://arxiv.org/abs/2001.08055)] – 2020 – **Up to two billion times acceleration of scientific simulations with deep neural architecture search** – M. F. Kasim, D. Watson-Parris, L. Deaconu, S. Oliver, P. Hatfield, D. H. Froula, G. Gregori, M. Jarvis, S. Khatiwala, J. Korenaga, J. Topp-Mugglestone, E. Viezzer, S. M. Vinko – *Science*

[[**Notes**](assets/dulacarnold2016.md)] [[Paper](https://arxiv.org/abs/1512.07679)] – 2016 – **Deep Reinforcement Learning in Large Discrete Action Spaces** – Gabriel Dulac-Arnold, Richard Evans, Hado van Hasselt, Peter Sunehag, Timothy Lillicrap, Jonathan Hunt, Timothy Mann, Theophane Weber, Thomas Degris, Ben Coppin – *Google Deepmind*

[[**Notes**](vandewiele2020.md)] [[Paper](https://arxiv.org/abs/2001.08116)] – 2020 – **Q-Learning in enormous action spaces via amortized approximate maximization** – Tom Van de Wiele, David Warde-Farley, Andriy Mnih & Volodymyr Mnih – *DeepMind report*

[[**Notes**](dzmitry2015.md)] [[Paper](https://arxiv.org/abs/1409.0473)] – 2015 – **Neural Machine Translation by Jointly Learning to Align and Translate** – Dzmitry Bahdanau, KyungHyun Cho, Yoshua Bengio – *International Conference of Learning Representations (ICLR 2015)*

[[**Notes**](dudik2011.md)] [[Paper](https://arxiv.org/abs/1103.4601)] – 2011 – **Doubly Robust Policy Evaluation and Learning** – Miroslav Dudík, John LangFord, Lihong Li – *Proceedings of the 28th International Conference on Machine Learning*

[[**Notes**](he2016.md)] [[Paper](https://arxiv.org/abs/1606.03667)] – 2016 – **Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads** – Ji He, Mari Ostendorf, Xiaodong He, Jianshu Chen, Jianfeng Gao, Lianfeng Gao, Lihong Li, Li Deng – *Microsoft Research and University of Washington*

[[**Notes**](mandel2016.md)] [[Paper](http://grail.cs.washington.edu/projects/nonstationaryeval/nonstationaryevalExtended.pdf)] – 2016 – **Offline Evaluation of Online Reinforcement Learning Algorithms** – Travis Mandel, Yun-En Liu, Emma Brunskill, Zoran Popovic – *Proceedings of the 30th AAAI Conference on Artificial Intelligence*

[[**Notes**](zhao2018.md)] [[Paper](https://ieeexplore.ieee.org/document/8396173)] – 2018 – **Handling Large-Scale Action Space in Deep Q Network** – Zhiheng Zhao, Yi Liang, Xiaoming Ji – *2018 International Conference on Artificial Intelligence and Big Data*

[[**Notes**](chollet2017.pdf)] [[Paper](https://arxiv.org/abs/1610.02357)] – 2017 – **Deep Learning with Depthwise Separable Convolutions** – François Chollet – *Google report*